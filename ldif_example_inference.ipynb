{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dbrrmZ8eTox"
   },
   "source": [
    "**To run this code, start up a kernel running at the ldif repository root, and attach to it**. The easiest way is to register an ldif conda environment with jupyter. From a terminal with that kernel currently active, run \n",
    "\n",
    "`python -m ipykernel install --user --name ldif-env --display-name \"LDIF+SIF Kernel\"`\n",
    "\n",
    "Then, within the notebook, click Kernel -> Change kernel -> LDIF+SIF Kernel. Once this is done all the following cells should run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7384,
     "status": "error",
     "timestamp": 1589835031370,
     "user": {
      "displayName": "Matheus Gadelha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj2xXjid6wi01YrxlMjBr9pQxZ5zhlynb3bBIEG=s64",
      "userId": "15418345690709714259"
     },
     "user_tz": 240
    },
    "id": "T7T20mZiF05M",
    "outputId": "d1d9161b-0c84-4505-8629-0f45d8cad114"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import trimesh\n",
    "from ldif.datasets import shapenet_np\n",
    "importlib.reload(shapenet_np)\n",
    "from ldif.util import geom_util\n",
    "importlib.reload(geom_util)\n",
    "from ldif.representation import structured_implicit_function\n",
    "importlib.reload(structured_implicit_function)\n",
    "from ldif.inference import predict\n",
    "importlib.reload(predict)\n",
    "from ldif.inference import experiment\n",
    "importlib.reload(experiment)\n",
    "from ldif.inference import example\n",
    "importlib.reload(example)\n",
    "from ldif.util import gaps_util\n",
    "importlib.reload(gaps_util)\n",
    "from ldif.inference import metrics\n",
    "importlib.reload(metrics)\n",
    "from ldif.util import random_util\n",
    "from ldif.util import file_util\n",
    "importlib.reload(random_util)\n",
    "from ldif.util.file_util import log\n",
    "log.set_level('error')  # Only show errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isdir('input_meshes/train/animal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzlbzhV3f7m8"
   },
   "source": [
    "Set the dataset directory to the output path root from the meshes2dataset.py command. See the README.md for more documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blub\n",
      "blub\n",
      "input_meshes/train/animal/\n",
      "train animal\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = 'input_meshes'\n",
    "e = example.InferenceExample.from_local_dataset_tokens(dataset_directory, \n",
    "                                                       'train', 'animal', 'blub') #, '3b9c905771244df7b6ed9420d56b12a9')\n",
    "# e = example.InferenceExample.from_directory('input_meshes/train/animals/blub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split': 'train', 'synset': 'animal', 'cat': 'animal', 'mesh_hash': 'blub', '_rgb_path': None, '_rgb_image': None, '_InferenceExample__archive': None, '_uniform_samples': None, '_near_surface_samples': None, '_grid': None, '_world2grid': None, '_gt_path': 'input_meshes/train/animal/blub.ply', '_tx': None, '_gaps_to_occnet': None, '_gt_mesh': None, '_tx_path': 'input_meshes/train/animal/blub/orig_to_gaps.txt', '_surface_samples': None, '_normalized_gt_mesh': None, '_r2n2_images': None, 'depth_native_res': 224, 'is_from_directory': True, '_dodeca_depth_and_normal_path': 'input_meshes/train/animal/blub/depth_and_normals.npz', '_directory_root': 'input_meshes/train/animal/blub', '_grid_path': 'input_meshes/train/animal/blub/coarse_grid.grd', 'precomputed_surface_samples_from_dodeca_path': 'input_meshes/train/animal/blub/surface_samples_from_dodeca.pts'}\n",
      "asdf\n",
      "input_meshes/train/animal/blub.ply\n",
      "<trimesh.Trimesh(vertices.shape=(7106, 3), faces.shape=(14208, 3))>\n"
     ]
    }
   ],
   "source": [
    "print(vars(e))\n",
    "print(e.gt_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSBYcHqsjbzH"
   },
   "outputs": [],
   "source": [
    "# The example objects lazily load the various data values as they are requested.\n",
    "# show() is interactive. Its output doesn't get saved with the .ipynb\n",
    "# gaps_util.mshview('input_meshes/train/animals/blub')\n",
    "gaps_util.mshview(e.gt_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oiDcFHAJgIwL"
   },
   "source": [
    "Encoders map from an example to the sif representation. The output is just a numpy array with the blob and implicit parameters.\n",
    "\n",
    "Decoders map from a sif vector to a variety of different outputs, such as a mesh, a set of inside/outside decisions at query points, an ellipsoid rendering, a txt file, or an interactive viewer session. Please see the decoder class methods for all the outputs.\n",
    "\n",
    "Both encoders and decoders can be loaded from the identifiers of the training jobs that generated them. Note that they are built dynamically, not frozen models. So the class constructor will generate the graph based on the current state of the dsif/ codebase in whatever client the adhoc_import used above and then try to restore the model weights. If you edit the code, reload the predict module, then make a model object, you can see how the changes in the code affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory not found: /path/to/trained_model_directory//sif-transcoder-ldif-autoencoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-34e1086067c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ldif-autoencoder'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mxid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Always 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     ckpt_idx=-1)  # -1 means newest\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/jryan/Documents/Github/ldif/ldif/inference/predict.py\u001b[0m in \u001b[0;36mfrom_modeldir\u001b[0;34m(cls, model_directory, model_name, experiment_name, xid, ckpt_idx, overrides, use_temp_ckpts, use_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m\"\"\"Creates a TrainedModel from a model directory root and name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     experiment = experiments.Experiment(model_directory, model_name,\n\u001b[0;32m--> 103\u001b[0;31m                                         experiment_name)\n\u001b[0m\u001b[1;32m    104\u001b[0m     return cls.from_experiment(experiment, xid, ckpt_idx, use_temp_ckpts,\n\u001b[1;32m    105\u001b[0m                                overrides, use_gpu, **kwargs)\n",
      "\u001b[0;32m/mnt/c/Users/jryan/Documents/Github/ldif/ldif/inference/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir, model_name, experiment_name)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \"Tried to glob for directory but didn't find one path. Found:\")\n\u001b[1;32m    245\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Directory not found: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Directory not found: /path/to/trained_model_directory//sif-transcoder-ldif-autoencoder"
     ]
    }
   ],
   "source": [
    "model_directory = '/path/to/trained_model_directory/'\n",
    "\n",
    "encoder = predict.DepthEncoder.from_modeldir(\n",
    "                    model_directory=model_directory,\n",
    "                    model_name='sif-transcoder',\n",
    "                    experiment_name='ldif-autoencoder',\n",
    "                    xid=1,  # Always 1\n",
    "                    ckpt_idx=-1)  # -1 means newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory not found: /path/to/trained_model_directory//sif-transcoder-ldif-autoencoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a9034c1ca34c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ldif-autoencoder'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mckpt_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )  # -1 means newest\n",
      "\u001b[0;32m/mnt/c/Users/jryan/Documents/Github/ldif/ldif/inference/predict.py\u001b[0m in \u001b[0;36mfrom_modeldir\u001b[0;34m(cls, model_directory, model_name, experiment_name, xid, ckpt_idx, overrides, use_temp_ckpts, use_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m\"\"\"Creates a TrainedModel from a model directory root and name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     experiment = experiments.Experiment(model_directory, model_name,\n\u001b[0;32m--> 103\u001b[0;31m                                         experiment_name)\n\u001b[0m\u001b[1;32m    104\u001b[0m     return cls.from_experiment(experiment, xid, ckpt_idx, use_temp_ckpts,\n\u001b[1;32m    105\u001b[0m                                overrides, use_gpu, **kwargs)\n",
      "\u001b[0;32m/mnt/c/Users/jryan/Documents/Github/ldif/ldif/inference/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir, model_name, experiment_name)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \"Tried to glob for directory but didn't find one path. Found:\")\n\u001b[1;32m    245\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Directory not found: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Directory not found: /path/to/trained_model_directory//sif-transcoder-ldif-autoencoder"
     ]
    }
   ],
   "source": [
    "decoder = predict.Decoder.from_modeldir(\n",
    "    model_directory=model_directory,\n",
    "    model_name='sif-transcoder',\n",
    "    experiment_name='ldif-autoencoder',\n",
    "    xid=1,\n",
    "    ckpt_idx=-1,\n",
    ")  # -1 means newest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the inference kernel is not installed, uncomment the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.use_inference_kernel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "height": 550
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17588,
     "status": "ok",
     "timestamp": 1586395358402,
     "user": {
      "displayName": "Kyle Genova",
      "photoUrl": "",
      "userId": "17726541240749045107"
     },
     "user_tz": 420
    },
    "id": "HJNbkCs4jZpi",
    "outputId": "1d7ce6d2-b369-4881-ca46-46b20136a74e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f4eaf3cc1611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgaps_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "embedding = encoder.run_example(e)\n",
    "mesh = decoder.extract_mesh(embedding, resolution=256)\n",
    "gaps_util.mshview(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1586217246923,
     "user": {
      "displayName": "Kyle Genova",
      "photoUrl": "",
      "userId": "17726541240749045107"
     },
     "user_tz": 420
    },
    "id": "QQ1dA-U81cRV",
    "outputId": "d550da21-10ca-4552-b7ed-d24ece0d84f1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e17025c7aba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IoU can be computed quickly:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "# IoU can be computed quickly:\n",
    "decoder.iou(embedding, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1586217257208,
     "user": {
      "displayName": "Kyle Genova",
      "photoUrl": "",
      "userId": "17726541240749045107"
     },
     "user_tz": 420
    },
    "id": "mED6GmtJ4XXC",
    "outputId": "50288437-c09d-4e6f-ef33-dbfcaa145ca6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2355ad9ddeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/data/test-sif.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "txt = decoder.savetxt(embedding, '/data/test-sif.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1586217258528,
     "user": {
      "displayName": "Kyle Genova",
      "photoUrl": "",
      "userId": "17726541240749045107"
     },
     "user_tz": 420
    },
    "id": "T2Am54Ft4h3f",
    "outputId": "57596147-6ff5-42fe-e65e-8d1814ad6e8f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mesh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4233fe6600d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mserialized_mesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/test-sif.ply'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mesh' is not defined"
     ]
    }
   ],
   "source": [
    "serialized_mesh = mesh.export('/data/test-sif.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35340,
     "status": "ok",
     "timestamp": 1578542446627,
     "user": {
      "displayName": "Kyle Genova",
      "photoUrl": "",
      "userId": "17726541240749045107"
     },
     "user_tz": 480
    },
    "id": "946_I6ar1ufU",
    "outputId": "f54301c2-d501-400c-b8db-4248a0cad143"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-97b164e510ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The other metrics take a few seconds:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "# The other metrics take a few seconds:\n",
    "metrics.print_all(embedding, decoder, e, resolution=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZMOWhNvj4KK"
   },
   "source": [
    "The decoder provides a variety of viewers. This one renders the templates as ellipsoids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3zzl8mOMuhf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-067c8a41a5ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "decoder.interactive_viewer(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "Copy of dsif-example-inference.ipynb",
   "provenance": [
    {
     "file_id": "1sz6TcvCEa2_Hedlxh9SkIHMT49KylOco",
     "timestamp": 1590520365636
    },
    {
     "file_id": "1UZg1eH7DJwKtv-LblDKDUAZtNX44sOm6",
     "timestamp": 1578511642213
    },
    {
     "file_id": "1E-PLFx7AgMOtuVYCZodAiEZxoBK3xiQC",
     "timestamp": 1571781313354
    }
   ]
  },
  "kernelspec": {
   "display_name": "LDIF+SIF Kernel",
   "language": "python",
   "name": "ldif-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
